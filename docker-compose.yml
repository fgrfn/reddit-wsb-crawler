version: '3.8'

services:
  wsb-crawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: wsb-crawler
    image: wsb-crawler:latest
    restart: unless-stopped
    
    environment:
      # Timezone
      - TZ=Europe/Berlin
      
      # Reddit API (REQUIRED)
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - REDDIT_USER_AGENT=${REDDIT_USER_AGENT:-python:wsb-crawler:v1.0.0 (by /u/youruser)}
      
      # Subreddits
      - SUBREDDITS=${SUBREDDITS:-wallstreetbets,wallstreetbetsGER}
      
      # NewsAPI (REQUIRED)
      - NEWSAPI_KEY=${NEWSAPI_KEY}
      - NEWSAPI_LANG=${NEWSAPI_LANG:-en}
      - NEWSAPI_WINDOW_HOURS=${NEWSAPI_WINDOW_HOURS:-48}
      
      # Discord (REQUIRED)
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
      - DISCORD_STATUS_UPDATE=${DISCORD_STATUS_UPDATE:-true}
      
      # Alert Thresholds
      - ALERT_MIN_ABS=${ALERT_MIN_ABS:-20}
      - ALERT_MIN_DELTA=${ALERT_MIN_DELTA:-10}
      - ALERT_RATIO=${ALERT_RATIO:-2.0}
      - ALERT_MIN_PRICE_MOVE=${ALERT_MIN_PRICE_MOVE:-5.0}
      - ALERT_MAX_PER_RUN=${ALERT_MAX_PER_RUN:-3}
      - ALERT_COOLDOWN_H=${ALERT_COOLDOWN_H:-4}
      
      # Optional: Alpha Vantage API
      - ALPHAVANTAGE_API_KEY=${ALPHAVANTAGE_API_KEY:-}
    
    env_file:
      - config/.env
    
    volumes:
      # Persistente Daten
      - ./data:/app/data
      - ./logs:/app/logs
      # Config (read-only)
      - ./config/.env:/app/config/.env:ro
    
    # Für scheduled runs mit cron
    # command: >
    #   sh -c "while true; do
    #     python src/run_crawler_headless.py;
    #     echo 'Crawl completed. Waiting 1 hour...';
    #     sleep 3600;
    #   done"
    
    # Logging-Konfiguration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    # Ressourcen-Limits (optional)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Optional: Scheduler-Service für regelmäßige Crawls
  wsb-crawler-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: wsb-crawler-scheduler
    image: wsb-crawler:latest
    restart: unless-stopped
    profiles:
      - scheduler
    
    environment:
      - TZ=Europe/Berlin
      # Crawl-Intervall in Sekunden (Standard: 1 Stunde)
      - CRAWL_INTERVAL=${CRAWL_INTERVAL:-3600}
      
      # Reddit API (REQUIRED)
      - REDDIT_CLIENT_ID=${REDDIT_CLIENT_ID}
      - REDDIT_CLIENT_SECRET=${REDDIT_CLIENT_SECRET}
      - REDDIT_USER_AGENT=${REDDIT_USER_AGENT:-python:wsb-crawler:v1.0.0 (by /u/youruser)}
      
      # Subreddits
      - SUBREDDITS=${SUBREDDITS:-wallstreetbets,wallstreetbetsGER}
      
      # NewsAPI (REQUIRED)
      - NEWSAPI_KEY=${NEWSAPI_KEY}
      - NEWSAPI_LANG=${NEWSAPI_LANG:-en}
      - NEWSAPI_WINDOW_HOURS=${NEWSAPI_WINDOW_HOURS:-48}
      
      # Discord (REQUIRED)
      - DISCORD_WEBHOOK_URL=${DISCORD_WEBHOOK_URL}
      - DISCORD_STATUS_UPDATE=${DISCORD_STATUS_UPDATE:-true}
      
      # Alert Thresholds
      - ALERT_MIN_ABS=${ALERT_MIN_ABS:-20}
      - ALERT_MIN_DELTA=${ALERT_MIN_DELTA:-10}
      - ALERT_RATIO=${ALERT_RATIO:-2.0}
      - ALERT_MIN_PRICE_MOVE=${ALERT_MIN_PRICE_MOVE:-5.0}
      - ALERT_MAX_PER_RUN=${ALERT_MAX_PER_RUN:-3}
      - ALERT_COOLDOWN_H=${ALERT_COOLDOWN_H:-4}
      
      # Optional: Alpha Vantage API
      - ALPHAVANTAGE_API_KEY=${ALPHAVANTAGE_API_KEY:-}
    
    env_file:
      - config/.env
    
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config/.env:/app/config/.env:ro
    
    command: >
      sh -c "
        echo 'Starting WSB-Crawler Scheduler...';
        echo 'Interval: $${CRAWL_INTERVAL:-3600} seconds';
        while true; do
          echo '[$(date)] Starting crawl...';
          python src/run_crawler_headless.py;
          EXIT_CODE=$$?;
          if [ $$EXIT_CODE -eq 0 ]; then
            echo '[$(date)] Crawl completed successfully';
          else
            echo '[$(date)] Crawl failed with exit code $$EXIT_CODE';
          fi;
          echo '[$(date)] Waiting $${CRAWL_INTERVAL:-3600} seconds until next crawl...';
          sleep $${CRAWL_INTERVAL:-3600};
        done
      "
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  wsb-data:
    driver: local
  wsb-logs:
    driver: local
