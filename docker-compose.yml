version: '3.8'

services:
  wsb-crawler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: wsb-crawler
    image: wsb-crawler:latest
    restart: unless-stopped
    
    environment:
      # Timezone
      - TZ=Europe/Berlin
    
    env_file:
      - config/.env
    
    volumes:
      # Persistente Daten
      - ./data:/app/data
      - ./logs:/app/logs
      # Config (read-only)
      - ./config/.env:/app/config/.env:ro
    
    # Für scheduled runs mit cron
    # command: >
    #   sh -c "while true; do
    #     python src/run_crawler_headless.py;
    #     echo 'Crawl completed. Waiting 1 hour...';
    #     sleep 3600;
    #   done"
    
    # Logging-Konfiguration
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    
    # Ressourcen-Limits (optional)
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Optional: Scheduler-Service für regelmäßige Crawls
  wsb-crawler-scheduler:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: wsb-crawler-scheduler
    image: wsb-crawler:latest
    restart: unless-stopped
    profiles:
      - scheduler
    
    environment:
      - TZ=Europe/Berlin
      # Crawl-Intervall in Sekunden (Standard: 1 Stunde)
      - CRAWL_INTERVAL=3600
    
    env_file:
      - config/.env
    
    volumes:
      - ./data:/app/data
      - ./logs:/app/logs
      - ./config/.env:/app/config/.env:ro
    
    command: >
      sh -c "
        echo 'Starting WSB-Crawler Scheduler...';
        echo 'Interval: $${CRAWL_INTERVAL:-3600} seconds';
        while true; do
          echo '[$(date)] Starting crawl...';
          python src/run_crawler_headless.py;
          EXIT_CODE=$$?;
          if [ $$EXIT_CODE -eq 0 ]; then
            echo '[$(date)] Crawl completed successfully';
          else
            echo '[$(date)] Crawl failed with exit code $$EXIT_CODE';
          fi;
          echo '[$(date)] Waiting $${CRAWL_INTERVAL:-3600} seconds until next crawl...';
          sleep $${CRAWL_INTERVAL:-3600};
        done
      "
    
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

volumes:
  wsb-data:
    driver: local
  wsb-logs:
    driver: local
