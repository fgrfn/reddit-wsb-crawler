import os
import pickle
import csv
import requests
import yfinance as yf
from pathlib import Path
from colorama import Fore, Style, init
from dotenv import load_dotenv
from concurrent.futures import ThreadPoolExecutor, as_completed
from ticker_utils import load_tickerlist
import logging
import glob

# üü¢ Farbkonsole aktivieren
init(autoreset=True)

# üìÅ Pfade
CSV_EXPORT_PATH = Path("data/output/latest_resolved_names.csv")
PKL_CACHE_PATH = Path("data/input/ticker_name_map.pkl")
CSV_CACHE_PATH = Path("data/input/ticker_name_map.csv")
PICKLE_DIR = Path("data/output/pickle")

# Logger einrichten
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

# üåê Anbieter-Resolver (parallel: Yahoo & Alpha Vantage)
def resolve_symbol_parallel(symbol):
    def from_yahoo():
        try:
            info = yf.Ticker(symbol).info
            name = info.get("longName") or info.get("shortName")
            if name and name != symbol:
                return "Yahoo", name
        except:
            pass
        return None

    def from_alpha():
        key = os.getenv("ALPHA_VANTAGE_API_KEY")
        if not key:
            return None
        try:
            url = f"https://www.alphavantage.co/query?function=OVERVIEW&symbol={symbol}&apikey={key}"
            r = requests.get(url, timeout=5)
            if r.ok:
                data = r.json()
                name = data.get("Name")
                if name:
                    return "Alpha", name
        except:
            pass
        return None

    with ThreadPoolExecutor() as ex:
        f_y = ex.submit(from_yahoo)
        f_a = ex.submit(from_alpha)
        done = []
        for f in as_completed([f_y, f_a]):
            result = f.result()
            if result:
                provider, name = result
                return symbol, name, provider
            done.append(f)
        return symbol, None, None

# üíæ Cache-Handling
def load_ticker_name_map():
    if PKL_CACHE_PATH.exists():
        with open(PKL_CACHE_PATH, "rb") as f:
            return pickle.load(f)
    return {}

def save_ticker_name_map(name_map):
    with open(PKL_CACHE_PATH, "wb") as f:
        pickle.dump(name_map, f)
    with open(CSV_CACHE_PATH, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Ticker", "Company"])
        for sym, name in sorted(name_map.items()):
            writer.writerow([sym, name])

# üß† Hauptfunktion
def resolve_from_hits():
    load_dotenv()

    print(f"\nüìú Lese Treffer aus: {LATEST_HITS_PATH}")
    if not LATEST_HITS_PATH.exists():
        print(f"{Fore.RED}‚ùå Trefferdatei nicht gefunden.")
        return

    with open(LATEST_HITS_PATH, "rb") as f:
        try:
            counter = pickle.load(f)
        except Exception as e:
            print(f"{Fore.RED}‚ùå Fehler beim Lesen: {e}")
            return

    if not counter:
        print(f"{Fore.YELLOW}‚ö™Ô∏è Keine Ticker in der Trefferliste.")
        return

    print(f"{Fore.LIGHTBLACK_EX}üìä Gesamt-Nennungen: {sum(v for v in counter.values() if isinstance(v, int))}")
    print(f"{Fore.LIGHTBLACK_EX}üîç Einzigartige Ticker: {len(counter)}")

    name_map = load_ticker_name_map()
    print(f"{Fore.LIGHTBLACK_EX}üì¶ Ticker im Cache: {len(name_map)}")

    uncached = sorted(s for s in counter if s not in name_map)
    print(f"{Fore.YELLOW}üÜï Neue Ticker zur Aufl√∂sung: {len(uncached)}\n")

    # Zeige an, welche Ticker aus dem Cache kommen
    if name_map:
        for sym in sorted(counter):
            if sym in name_map:
                print(f"{Fore.LIGHTGREEN_EX}üóÉÔ∏è {sym:<6}{Style.RESET_ALL} ‚Üí {name_map[sym]} (aus Cache)")

    if not uncached:
        print(f"{Fore.GREEN}‚úÖ Alle Ticker bereits bekannt ‚Äì nichts zu tun.")
        return

    # Versuche lokale Ticker-Liste
    tickers = load_tickerlist()
    symbol_to_name = dict(zip(tickers["Symbol"], tickers["Security Name"]))

    resolved = {}
    fallback_needed = []
    for sym in uncached:
        name = symbol_to_name.get(sym)
        if name:
            print(f"{Fore.GREEN}‚úÖ {Fore.CYAN}{sym:<6}{Style.RESET_ALL} ‚Üí {name} (lokale Liste)")
            logger.info(f"‚úÖ {sym} ‚Üí {name} (lokale Liste)")
            resolved[sym] = name
        else:
            print(f"{Fore.YELLOW}‚ö†Ô∏è {sym:<6} nicht in lokaler Liste, versuche Fallback (API)...")
            logger.warning(f"‚ö†Ô∏è {sym} nicht in lokaler Liste, versuche Fallback (API)...")
            fallback_needed.append(sym)

    # Fallback: API (parallel)
    if fallback_needed:
        with ThreadPoolExecutor(max_workers=10) as pool:
            futures = {pool.submit(resolve_symbol_parallel, s): s for s in fallback_needed}
            for future in as_completed(futures):
                sym, name, src = future.result()
                if name:
                    print(f"{Fore.GREEN}‚úÖ {Fore.CYAN}{sym:<6}{Style.RESET_ALL} ‚Üí {name} ({src} Fallback)")
                    logger.info(f"‚úÖ {sym} ‚Üí {name} ({src} Fallback)")
                    resolved[sym] = name
                else:
                    print(f"{Fore.LIGHTBLACK_EX}üï≥Ô∏è {sym:<6} konnte nicht aufgel√∂st werden")
                    logger.error(f"‚ùå {sym} konnte nicht aufgel√∂st werden")

    if resolved:
        name_map.update(resolved)
        save_ticker_name_map(name_map)
        print(f"\n{Fore.GREEN}üíæ Cache aktualisiert mit {len(resolved)} neuen Eintr√§gen.")

        CSV_EXPORT_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(CSV_EXPORT_PATH, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Ticker", "Company"])
            for sym in sorted(resolved):
                writer.writerow([sym, resolved[sym]])
        print(f"{Fore.BLUE}üìé Exportiert nach: {CSV_EXPORT_PATH}")
    else:
        print(f"\n{Fore.YELLOW}‚ö†Ô∏è Keine neuen Namen aufl√∂sbar.")

print("Resolver l√§uft!")

if __name__ == "__main__":
    logger.info(f"Starte resolve_latest_hits.py (cwd={os.getcwd()})")
    resolve_from_hits()

    PICKLE_DIR = Path("data/output/pickle")
    pickle_files = sorted(PICKLE_DIR.glob("*.pkl"), reverse=True)
    if not pickle_files:
        print("‚ùå Keine Pickle-Datei gefunden.")
        exit(1)
    latest_pickle = pickle_files[0]
    print(f"üìú Lese Treffer aus: {latest_pickle}")

    with open(latest_pickle, "rb") as f:
        counter = pickle.load(f)

    if not counter:
        print(f"{Fore.YELLOW}‚ö™Ô∏è Keine Ticker in der neuesten Pickle-Datei.")
        exit(0)

    print(f"{Fore.LIGHTBLACK_EX}üìä Gesamt-Nennungen in Pickle-Datei: {sum(v for v in counter.values() if isinstance(v, int))}")
    print(f"{Fore.LIGHTBLACK_EX}üîç Einzigartige Ticker in Pickle-Datei: {len(counter)}")

    name_map = load_ticker_name_map()
    print(f"{Fore.LIGHTBLACK_EX}üì¶ Ticker im Cache: {len(name_map)}")

    uncached = sorted(s for s in counter if s not in name_map)
    print(f"{Fore.YELLOW}üÜï Neue Ticker zur Aufl√∂sung in Pickle-Datei: {len(uncached)}\n")

    # Zeige an, welche Ticker aus dem Cache kommen
    if name_map:
        for sym in sorted(counter):
            if sym in name_map:
                print(f"{Fore.LIGHTGREEN_EX}üóÉÔ∏è {sym:<6}{Style.RESET_ALL} ‚Üí {name_map[sym]} (aus Cache)")

    if not uncached:
        print(f"{Fore.GREEN}‚úÖ Alle Ticker in der Pickle-Datei bereits bekannt ‚Äì nichts zu tun.")
        exit(0)

    # Versuche lokale Ticker-Liste
    tickers = load_tickerlist()
    symbol_to_name = dict(zip(tickers["Symbol"], tickers["Security Name"]))

    resolved = {}
    fallback_needed = []
    for sym in uncached:
        name = symbol_to_name.get(sym)
        if name:
            print(f"{Fore.GREEN}‚úÖ {Fore.CYAN}{sym:<6}{Style.RESET_ALL} ‚Üí {name} (lokale Liste)")
            logger.info(f"‚úÖ {sym} ‚Üí {name} (lokale Liste)")
            resolved[sym] = name
        else:
            print(f"{Fore.YELLOW}‚ö†Ô∏è {sym:<6} nicht in lokaler Liste, versuche Fallback (API)...")
            logger.warning(f"‚ö†Ô∏è {sym} nicht in lokaler Liste, versuche Fallback (API)...")
            fallback_needed.append(sym)

    # Fallback: API (parallel)
    if fallback_needed:
        with ThreadPoolExecutor(max_workers=10) as pool:
            futures = {pool.submit(resolve_symbol_parallel, s): s for s in fallback_needed}
            for future in as_completed(futures):
                sym, name, src = future.result()
                if name:
                    print(f"{Fore.GREEN}‚úÖ {Fore.CYAN}{sym:<6}{Style.RESET_ALL} ‚Üí {name} ({src} Fallback)")
                    logger.info(f"‚úÖ {sym} ‚Üí {name} ({src} Fallback)")
                    resolved[sym] = name
                else:
                    print(f"{Fore.LIGHTBLACK_EX}üï≥Ô∏è {sym:<6} konnte nicht aufgel√∂st werden")
                    logger.error(f"‚ùå {sym} konnte nicht aufgel√∂st werden")

    if resolved:
        name_map.update(resolved)
        save_ticker_name_map(name_map)
        print(f"\n{Fore.GREEN}üíæ Cache aktualisiert mit {len(resolved)} neuen Eintr√§gen.")

        CSV_EXPORT_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(CSV_EXPORT_PATH, "w", newline="", encoding="utf-8") as f:
            writer = csv.writer(f)
            writer.writerow(["Ticker", "Company"])
            for sym in sorted(resolved):
                writer.writerow([sym, resolved[sym]])
        print(f"{Fore.BLUE}üìé Exportiert nach: {CSV_EXPORT_PATH}")
    else:
        print(f"\n{Fore.YELLOW}‚ö†Ô∏è Keine neuen Namen aufl√∂sbar.")
