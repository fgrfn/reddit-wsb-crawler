import os
import openai
import pickle
from dotenv import load_dotenv
from datetime import datetime
from collections import defaultdict
import logging
from run_crawler_headless import get_yf_price  # Importiere die Funktion, falls n√∂tig

openai.api_key = None

def load_env():
    load_dotenv(dotenv_path="config/.env")
    key = os.getenv("OPENAI_API_KEY")
    if not key:
        raise ValueError("‚ùå OPENAI_API_KEY fehlt in config/.env")
    global openai
    openai.api_key = key

def load_latest_pickle():
    files = sorted(os.listdir("data/output/pickle"), reverse=True)
    for file in files:
        if file.endswith(".pkl"):
            with open(f"data/output/pickle/{file}", "rb") as f:
                return pickle.load(f), file
    raise FileNotFoundError("Keine .pkl-Dateien gefunden.")

def extract_text(result, ticker):
    texts = []
    for sr_name, sr_data in result.get("subreddits", {}).items():
        for s, hits in sr_data["symbol_hits"].items():
            if s == ticker and hits >= 1:
                # Hier KEINE Subreddit- oder Nennungs-Infos mehr!
                texts.append("")  # oder: texts.append(f"{s}")
    return "\n".join([t for t in texts if t])

def summarize_ticker(ticker, context):
    print(f"üìÑ Sende {ticker}-Kontext an OpenAI ...")
    prompt = (
        f"Fasse die wichtigsten Erkenntnisse aus Reddit-Diskussionen zum Aktienk√ºrzel {ticker} zusammen:\n"
        f"{context}\n\n"
        f"Bitte beantworte folgende Punkte in 3‚Äì5 S√§tzen:\n"
        f"- Wie ist die allgemeine Stimmung (positiv, negativ, gemischt)?\n"
        f"- Welche konkreten Gr√ºnde, Argumente oder Trends werden genannt?\n"
        f"- Gibt es besondere Ereignisse, Nachrichten oder Meinungen, die h√§ufig erw√§hnt werden?\n"
        f"Formuliere sachlich, kompakt und ohne Wiederholungen. "
        f"Beziehe dich auf den aktuellen B√∂rsenkurs und relevante B√∂rsennachrichten, falls vorhanden. "
        f"Verwende ausschlie√ülich wahre und aktuelle Fakten, keine erfundenen, fiktiven oder hypothetischen Inhalte. "
        f"Erw√§hne NICHT, wie oft oder in welchen Subreddits der Ticker genannt wurde. "
        f"Verzichte auf S√§tze wie 'Der Ticker wurde X-mal erw√§hnt' oder 'In r/wallstreetbets wurde Y-mal dar√ºber gesprochen'."
    )
    try:
        response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Du bist Warren Buffett, ein US-amerikanischer Investor, Unternehmer und Philanthrop ‚Äì bekannt als einer der erfolgreichsten Anleger der Geschichte und analysiert die Stimmung der Reddit Community. Dein Ziel ist es, Trendaktien fr√ºhzeitig zu erkennen, um entsprechend vor einem 'Hype' oder 'Gamma Squeeze' zu kaufen und mit Gewinn zu verkaufen."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
            max_tokens=500
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        logging.error(f"OpenAI-Fehler f√ºr {ticker}: {e}")
        return f"‚ùå Fehler f√ºr {ticker}: {e}"

def get_yf_news(symbol):
    import yfinance as yf
    try:
        ticker = yf.Ticker(symbol)
        news = ticker.news  # Gibt eine Liste von Dicts zur√ºck
        # Filtere nur News mit Titel und (optional) passendem Symbol
        headlines = [item.get("title") for item in news if "title" in item and (item.get("relatedTickers") is None or symbol in item.get("relatedTickers", []))]
        return headlines[:5]  # z.B. die 5 aktuellsten Headlines
    except Exception as e:
        print(f"News-Abfrage f√ºr {symbol} fehlgeschlagen: {e}")
        return []

def build_context_with_yahoo(ticker, kursdaten, news_headlines=None):
    kurs_str = f"Aktueller Kurs: {kursdaten.get('regular', 'unbekannt')} {kursdaten.get('currency', 'USD')}, " \
               f"Ver√§nderung: {kursdaten.get('change', 'unbekannt')} ({kursdaten.get('changePercent', 'unbekannt')}%)"
    news_str = ""
    if news_headlines:
        news_str = "\nAktuelle Nachrichten:\n" + "\n".join(f"- {headline}" for headline in news_headlines)
    return f"{kurs_str}\n{news_str}\nEs liegen keine konkreten Reddit-Diskussionsinhalte vor."

def main():
    load_env()
    result, filename = load_latest_pickle()
    print(f"üì• Verarbeite: {filename}")

    relevant = result.get("relevant", {})
    summaries = {}

    for ticker, count in relevant.items():
        if count < 10:
            continue  # nur ‚Äûdiskussionsreiche‚Äú Ticker
        kursdaten = get_yf_price(ticker)
        news_headlines = get_yf_news(ticker)
        context = build_context_with_yahoo(ticker, kursdaten, news_headlines)
        summary = summarize_ticker(ticker, context)
        summaries[ticker] = summary

    # üìÅ Ergebnisse speichern
    ts = datetime.now().strftime("%Y%m%d-%H%M")
    out_path = f"data/output/summaries/{ts}_ai_trendberichte.md"
    os.makedirs(os.path.dirname(out_path), exist_ok=True)

    with open(out_path, "w", encoding="utf-8") as f:
        for ticker, summary in summaries.items():
            f.write(f"## {ticker}\n{summary}\n\n")

    print(f"\n‚úÖ Zusammenfassungen gespeichert unter: {out_path}")

if __name__ == "__main__":
    main()
